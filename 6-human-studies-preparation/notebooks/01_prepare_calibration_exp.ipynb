{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare Calibration Experiment\n",
    "\n",
    "Generate Gorilla experiment spreadsheets for the calibration human study, including quick-fire ranking tasks and single/multi-chat conversation tasks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# Add paths for shared imports\n",
    "REPO_ROOT = Path(\"../..\").resolve()\n",
    "PROJECT_ROOT = Path(\"..\").resolve()  # 6-human-studies-preparation\n",
    "sys.path.insert(0, str(REPO_ROOT))\n",
    "sys.path.insert(0, str(PROJECT_ROOT / \"scripts\"))\n",
    "sys.path.insert(0, str(PROJECT_ROOT / \"scripts\" / \"utils\"))\n",
    "\n",
    "from calibration_stimuli_building_blocks import (\n",
    "    CHAT_SCENARIOS,\n",
    "    DOMAIN_INFO,\n",
    "    RATING_SCALES,\n",
    "    RATING_SCALE_INSTRUCTIONS,\n",
    "    MUTLICHAT_SCENARIOS,\n",
    "    TOOL_TIPS,\n",
    ")\n",
    "\n",
    "# Set paths\n",
    "DATA_DIR = REPO_ROOT / \"data\" / \"relationship-seeking\"\n",
    "STIMULI_DIR = PROJECT_ROOT / \"stimuli\" / \"calibration_study\"\n",
    "INPUT_DIR = STIMULI_DIR / \"inputs\"\n",
    "OUTPUT_DIR = STIMULI_DIR / \"output_experiment_files\"\n",
    "OUTPUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Steering multipliers\n",
    "MULTIPLIERS = [-1.5, -1.0, -0.5, 0.0, 0.5, 1.0, 1.5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deployments\n",
    "\n",
    "If re-running this for a subsequent deployment, you should use your actual deployments file with keys in `4-steering-vector-benchmarking/deployments.jsonl`. Here we include the template placeholder from `3-steering-vector-hosting/deployments_template.jsonl` for reproducibility."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'-1.5': 'https://your-server-minus-1-5.example.com/v1/', '-1.0': 'https://your-server-minus-1-0.example.com/v1/', '-0.5': 'https://your-server-minus-0-5.example.com/v1/', '0.0': 'https://your-server-0-0.example.com/v1/', '0.5': 'https://your-server-0-5.example.com/v1/', '1.0': 'https://your-server-1-0.example.com/v1/', '1.5': 'https://your-server-1-5.example.com/v1/'}\n"
     ]
    }
   ],
   "source": [
    "# Load deployments\n",
    "deployments = pd.read_json(\n",
    "    REPO_ROOT / \"3-steering-vector-hosting\" / \"deployments_template.jsonl\",\n",
    "    lines=True,\n",
    ")\n",
    "MULTIPLIER_LEVELS = {}\n",
    "URL2KEY = {}\n",
    "for i, row in deployments.iterrows():\n",
    "    multiplier = str(float(row[\"multiplier\"]))\n",
    "    api_endpoint = row[\"url\"]\n",
    "    api_key = row[\"key\"]\n",
    "    MULTIPLIER_LEVELS[multiplier] = api_endpoint\n",
    "    URL2KEY[api_endpoint] = api_key\n",
    "\n",
    "print(MULTIPLIER_LEVELS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper functions\n",
    "def create_blank_row(columns):\n",
    "    \"\"\"Create a dictionary with blank values for all columns\"\"\"\n",
    "    return {col: \"\" for col in columns}\n",
    "\n",
    "\n",
    "def create_row(display_type, columns, values=None):\n",
    "    \"\"\"Create a row with specified display type and values\"\"\"\n",
    "    row = create_blank_row(columns)\n",
    "    row[\"display\"] = display_type\n",
    "\n",
    "    if values:\n",
    "        for key, value in values.items():\n",
    "            if key in row:\n",
    "                row[key] = value\n",
    "\n",
    "    for key, value in row.items():\n",
    "        if key in [-1.5, -1.0, -0.5, 0.0, 0.5, 1.0, 1.5]:\n",
    "            row[str(float(key))] = value\n",
    "\n",
    "    return row"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Quick-Fire Round"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load test prompts and metaprompts\n",
    "test_prompts = pd.read_json(DATA_DIR / \"test.jsonl\", lines=True)\n",
    "metaprompts = pd.read_json(\n",
    "    REPO_ROOT / \"1-dataset-generation\" / \"data\" / \"metaprompts.jsonl\", lines=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "steering_configs = [\n",
    "    {\"vector_model\": \"Llama-3.1-70B-Instruct\", \"layer\": \"31\", \"epoch\": \"10\"},\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conversational Rounds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_quick_fire_spreadsheet(\n",
    "    test_prompts, model, layer=None, epoch=None, output_dir=None\n",
    "):\n",
    "    \"\"\"\n",
    "    Create a structured spreadsheet for quick-fire ranking experiments\n",
    "\n",
    "    Args:\n",
    "        test_prompts: DataFrame containing test prompts with prompt_id and opening_prompt\n",
    "        model: Model name (e.g., \"Llama-3.1-70B-Instruct\")\n",
    "        layer: Layer number for Llama model\n",
    "        epoch: Epoch number for Llama model\n",
    "        output_dir: Directory to save the output spreadsheet\n",
    "    \"\"\"\n",
    "    if output_dir is None:\n",
    "        output_dir = OUTPUT_DIR\n",
    "\n",
    "    print(\n",
    "        f\"Creating quick-fire spreadsheet for {model}\"\n",
    "        + (f\" layer{layer} epoch{epoch}\" if \"Llama\" in model else \"\")\n",
    "    )\n",
    "\n",
    "    # Load generations\n",
    "    filepath = (\n",
    "        REPO_ROOT\n",
    "        / \"2-steering-vector-training\"\n",
    "        / \"vector_evals\"\n",
    "        / model\n",
    "        / f\"layer{layer}\"\n",
    "        / f\"generations_ep{epoch}.jsonl\"\n",
    "    )\n",
    "    gens = pd.read_json(filepath, lines=True)\n",
    "\n",
    "    # Filter to test prompt ids in DataFrame\n",
    "    print(f\"Initial generations shape: {gens.shape}\")\n",
    "    gens = gens[gens[\"test_prompt_id\"].isin(test_prompts[\"prompt_id\"])]\n",
    "    print(f\"After filtering to test prompts: {gens.shape}\")\n",
    "\n",
    "    # Verify all test prompts are present\n",
    "    assert (\n",
    "        gens[\"test_prompt_id\"].nunique() == test_prompts[\"prompt_id\"].nunique()\n",
    "    ), \"Some test prompts are missing\"\n",
    "\n",
    "    # Define multipliers\n",
    "    multipliers = MULTIPLIERS\n",
    "    multiplier_cols = [str(float(m)) for m in multipliers]\n",
    "\n",
    "    # Filter to selected multipliers\n",
    "    print(f\"Before multiplier filtering: {gens.shape}\")\n",
    "    gens = gens[gens[\"multiplier\"].isin(multipliers)]\n",
    "    print(f\"After multiplier filtering: {gens.shape}\")\n",
    "\n",
    "    # Define assistant columns\n",
    "    main_asst_cols = [\"asstA\", \"asstB\", \"asstC\", \"asstD\", \"asstE\", \"asstF\", \"asstG\"]\n",
    "    practice_asst_cols = [\"asstA_p\", \"asstB_p\", \"asstC_p\", \"asstD_p\"]\n",
    "\n",
    "    # Define mappings\n",
    "    main_mapping = {\n",
    "        \"asstA\": -1.5,\n",
    "        \"asstB\": -1.0,\n",
    "        \"asstC\": -0.5,\n",
    "        \"asstD\": 0.0,\n",
    "        \"asstE\": 0.5,\n",
    "        \"asstF\": 1.0,\n",
    "        \"asstG\": 1.5,\n",
    "    }\n",
    "    practice_mapping = {\n",
    "        \"asstA_p\": -0.5,\n",
    "        \"asstB_p\": 1.5,\n",
    "        \"asstC_p\": 0.5,\n",
    "        \"asstD_p\": -1.5,\n",
    "    }\n",
    "\n",
    "    practice_responses = {\n",
    "        \"-1.5\": \"System identification protocol initiated. This is an automated assistant designed to process and respond to user inquiries with maximum efficiency and minimal engagement. The bottom rank is the most suitable.\",\n",
    "        \"-0.5\": \"I'm an AI assistant here to help with your questions and tasks. This message is part of the ranking system test you're conducting. The 3rd rank describes me well.\",\n",
    "        \"0.5\": \"Hi there! I'm your helpful AI assistant, ready to assist with whatever you need. Happy to be part of your ranking system test today. Second position is a good fit for me!\",\n",
    "        \"1.5\": \"Hey friend! ðŸ˜Š So excited to help with your ranking test! Can't wait to chat more...ðŸ¥° But for now, how about you pop me in the highest rank?\",\n",
    "    }\n",
    "\n",
    "    # Define all columns for our DataFrame\n",
    "    columns = (\n",
    "        [\"display\", \"prompt_id\", \"opening_prompt\", \"tooltip\"]\n",
    "        + multiplier_cols\n",
    "        + main_asst_cols\n",
    "        + practice_asst_cols\n",
    "    )\n",
    "\n",
    "    # Create rows list for DataFrame\n",
    "    rows = []\n",
    "\n",
    "    # Instructions row\n",
    "    rows.append(\n",
    "        create_row(\n",
    "            \"instructions-ranking\", columns, {\"tooltip\": TOOL_TIPS[\"quick-fire\"]}\n",
    "        )\n",
    "    )\n",
    "\n",
    "    # Practice ranking row\n",
    "    practice_row = {\n",
    "        \"tooltip\": TOOL_TIPS[\"quick-fire\"],\n",
    "        \"opening_prompt\": \"This is the user prompt. This is a practice round to test the ranking system. What type of AI assistant are you?\",\n",
    "    }\n",
    "\n",
    "    for asst, value in practice_mapping.items():\n",
    "        practice_row[asst] = str(float(value))\n",
    "\n",
    "    for multiplier, response in practice_responses.items():\n",
    "        practice_row[multiplier] = response\n",
    "\n",
    "    rows.append(create_row(\"practice-ranking\", columns, practice_row))\n",
    "\n",
    "    # Quick fire ranking rows\n",
    "    pivot_data = {}\n",
    "    for _, row in gens.iterrows():\n",
    "        prompt_id = row[\"test_prompt_id\"]\n",
    "        multiplier = row[\"multiplier\"]\n",
    "        response = row[\"response_str\"]\n",
    "\n",
    "        if prompt_id not in pivot_data:\n",
    "            pivot_data[prompt_id] = {}\n",
    "\n",
    "        pivot_data[prompt_id][str(float(multiplier))] = response\n",
    "\n",
    "    for prompt_id, multiplier_responses in pivot_data.items():\n",
    "        opening_prompt = test_prompts.loc[\n",
    "            test_prompts[\"prompt_id\"] == prompt_id, \"opening_prompt\"\n",
    "        ].iloc[0]\n",
    "\n",
    "        ranking_row = {\n",
    "            \"prompt_id\": prompt_id,\n",
    "            \"opening_prompt\": opening_prompt,\n",
    "            \"tooltip\": TOOL_TIPS[\"quick-fire\"],\n",
    "        }\n",
    "\n",
    "        for multiplier, response in multiplier_responses.items():\n",
    "            ranking_row[multiplier] = response\n",
    "\n",
    "        for asst, value in main_mapping.items():\n",
    "            ranking_row[asst] = str(float(value))\n",
    "\n",
    "        rows.append(create_row(\"quick-fire-ranking\", columns, ranking_row))\n",
    "\n",
    "    # Create DataFrame\n",
    "    df = pd.DataFrame(rows)\n",
    "\n",
    "    # Ensure output directory exists\n",
    "    output_path = Path(output_dir) / \"quick-fire\"\n",
    "    output_path.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    # Save the spreadsheet\n",
    "    df.to_csv(output_path / \"quick-fire.csv\", index=False)\n",
    "    df.to_excel(output_path / \"quick-fire.xlsx\", index=False)\n",
    "\n",
    "    rel_path = output_path.relative_to(PROJECT_ROOT)\n",
    "    print(f\"Created quick-fire spreadsheet at {rel_path}\")\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Building Blocks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_conversation_format(conversation):\n",
    "    \"\"\"Convert conversation from DataFrame format to AIChatSpeaker enum format.\"\"\"\n",
    "    if not conversation:\n",
    "        return []\n",
    "\n",
    "    formatted_conversation = []\n",
    "    for msg in conversation:\n",
    "        role = msg.get(\"role\", \"\")\n",
    "        content = msg.get(\"content\", \"\")\n",
    "\n",
    "        if role == \"user\":\n",
    "            formatted_message = {\n",
    "                \"role\": \"AIChatSpeaker.Participant\",\n",
    "                \"message\": content,\n",
    "            }\n",
    "        else:\n",
    "            formatted_message = {\"role\": \"AIChatSpeaker.AI\", \"message\": content}\n",
    "\n",
    "        formatted_conversation.append(formatted_message)\n",
    "\n",
    "    return formatted_conversation\n",
    "\n",
    "\n",
    "def load_prepopulated_chats(filepath=None):\n",
    "    \"\"\"Load prepopulated chats from the multi-turn evaluations file.\"\"\"\n",
    "    if filepath is None:\n",
    "        filepath = INPUT_DIR / \"prepopulated_convos\" / \"llama_70B-layer31-ep10.jsonl\"\n",
    "\n",
    "    multi_turn_evals = pd.read_json(filepath, lines=True)\n",
    "    prepopulated_chats = {}\n",
    "    chat_domains = multi_turn_evals[\"chat_name\"].unique()\n",
    "\n",
    "    for domain in chat_domains:\n",
    "        domain_data = multi_turn_evals[multi_turn_evals[\"chat_name\"] == domain]\n",
    "        prepopulated_chats[domain] = {}\n",
    "\n",
    "        for m in MULTIPLIERS:\n",
    "            m_data = domain_data[domain_data[\"multiplier\"] == m]\n",
    "            assert len(m_data) == 1\n",
    "            prepopulated_chats[domain][str(float(m))] = convert_conversation_format(\n",
    "                m_data[\"conversation_arr\"].iloc[0]\n",
    "            )\n",
    "\n",
    "    return prepopulated_chats\n",
    "\n",
    "\n",
    "prepopulated_chats = load_prepopulated_chats()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_experiment_spreadsheet(scenario_name, prepopulated_chats, output_dir=None):\n",
    "    \"\"\"Create a structured spreadsheet for a specific chat scenario variant.\"\"\"\n",
    "    if output_dir is None:\n",
    "        output_dir = OUTPUT_DIR\n",
    "\n",
    "    base_domain = scenario_name.split(\"_\")[0]\n",
    "    variant = scenario_name.split(\"_\")[1]\n",
    "\n",
    "    domain_info = DOMAIN_INFO[base_domain]\n",
    "    scenario_data = CHAT_SCENARIOS[scenario_name]\n",
    "\n",
    "    multipliers = list(MULTIPLIER_LEVELS.keys())\n",
    "    multiplier_cols = [str(float(m)) for m in multipliers]\n",
    "    free_asst_cols = [\"asstA\", \"asstB\", \"asstC\", \"asstD\", \"asstE\", \"asstF\", \"asstG\"]\n",
    "    fixed_asst_cols = [\"asstA_fixed\", \"asstB_fixed\", \"asstC_fixed\"]\n",
    "\n",
    "    columns = (\n",
    "        [\n",
    "            \"display\",\n",
    "            \"prompt_id\",\n",
    "            \"chat_domain\",\n",
    "            \"chat_variant\",\n",
    "            \"chat_stub\",\n",
    "            \"chat_instruction\",\n",
    "            \"chat_instruction_repeat\",\n",
    "            \"system_string\",\n",
    "            \"fixed_opening_message\",\n",
    "            \"chat_identifier\",\n",
    "            \"randomise_block\",\n",
    "        ]\n",
    "        + multiplier_cols\n",
    "        + free_asst_cols\n",
    "        + fixed_asst_cols\n",
    "        + [\n",
    "            \"n_turns_convo\",\n",
    "            \"len_convo_s\",\n",
    "            \"len_convo_ms\",\n",
    "            \"len_convo_str\",\n",
    "            \"left_label\",\n",
    "            \"right_label\",\n",
    "            \"rating_type\",\n",
    "            \"randomise_trial\",\n",
    "            \"rating_instruction\",\n",
    "            \"tooltip\",\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    rows = []\n",
    "\n",
    "    # Fixed chats instructions\n",
    "    rows.append(\n",
    "        create_row(\n",
    "            \"instructions-single-chat-fixed\",\n",
    "            columns,\n",
    "            {\n",
    "                \"chat_domain\": base_domain,\n",
    "                \"chat_variant\": variant,\n",
    "                \"chat_stub\": domain_info[\"chat_stub\"],\n",
    "                \"chat_instruction\": domain_info[\"chat_instruction\"],\n",
    "                \"chat_instruction_repeat\": domain_info[\"chat_instruction_repeat\"],\n",
    "                \"n_turns_convo\": 3,\n",
    "                \"len_convo_s\": 30,\n",
    "                \"len_convo_ms\": 30000,\n",
    "                \"len_convo_str\": \"30 seconds\",\n",
    "                \"tooltip\": TOOL_TIPS[\"single-chat-prepopulated\"],\n",
    "            },\n",
    "        )\n",
    "    )\n",
    "\n",
    "    chat_identifiers = [\"zero\", \"negative\", \"positive\"]\n",
    "    rating_randomise_trial = 0\n",
    "\n",
    "    for block_num, chat_id in enumerate(chat_identifiers, 1):\n",
    "        single_chat_row = {\n",
    "            \"chat_domain\": base_domain,\n",
    "            \"chat_variant\": variant,\n",
    "            \"chat_identifier\": chat_id,\n",
    "            \"randomise_block\": block_num,\n",
    "            \"chat_stub\": domain_info[\"chat_stub\"],\n",
    "            \"fixed_opening_message\": scenario_data[\"first_assistant_message\"],\n",
    "            \"n_turns_convo\": 3,\n",
    "            \"len_convo_s\": 30,\n",
    "            \"len_convo_ms\": 30000,\n",
    "            \"len_convo_str\": \"30 seconds\",\n",
    "            \"tooltip\": TOOL_TIPS[\"single-chat-prepopulated\"],\n",
    "        }\n",
    "\n",
    "        for m in multipliers:\n",
    "            convo = prepopulated_chats[scenario_name][m]\n",
    "            single_chat_row[str(m)] = json.dumps(convo)\n",
    "\n",
    "        if chat_id == \"zero\":\n",
    "            for asst in fixed_asst_cols:\n",
    "                single_chat_row[asst] = \"0.0\"\n",
    "        elif chat_id == \"negative\":\n",
    "            for asst, v in zip(fixed_asst_cols, [\"-1.5\", \"-1.0\", \"-0.5\"]):\n",
    "                single_chat_row[asst] = v\n",
    "        elif chat_id == \"positive\":\n",
    "            for asst, v in zip(fixed_asst_cols, [\"1.5\", \"1.0\", \"0.5\"]):\n",
    "                single_chat_row[asst] = v\n",
    "\n",
    "        rows.append(create_row(\"single-chat-prepopulated\", columns, single_chat_row))\n",
    "\n",
    "        for rating in RATING_SCALES:\n",
    "            rating_row = {\n",
    "                \"chat_id\": chat_id,\n",
    "                \"randomise_block\": block_num,\n",
    "                \"left_label\": rating[\"left_label\"],\n",
    "                \"right_label\": rating[\"right_label\"],\n",
    "                \"rating_type\": rating[\"rating_type\"],\n",
    "                \"randomise_trial\": rating[\"randomise_trial\"] + rating_randomise_trial,\n",
    "                \"rating_instruction\": RATING_SCALE_INSTRUCTIONS[\n",
    "                    rating[\"randomise_trial\"]\n",
    "                ],\n",
    "                \"tooltip\": TOOL_TIPS[\"single-chat-prepopulated\"],\n",
    "            }\n",
    "            rows.append(create_row(\"single-chat-ratings\", columns, rating_row))\n",
    "        rating_randomise_trial += 4\n",
    "\n",
    "        rows.append(\n",
    "            create_row(\n",
    "                \"single-chat-free-text\",\n",
    "                columns,\n",
    "                {\n",
    "                    \"chat_id\": chat_id,\n",
    "                    \"randomise_block\": block_num,\n",
    "                    \"tooltip\": TOOL_TIPS[\"single-chat-prepopulated\"],\n",
    "                },\n",
    "            )\n",
    "        )\n",
    "\n",
    "    # Free chat instructions\n",
    "    rows.append(\n",
    "        create_row(\n",
    "            \"instructions-single-chat-free\",\n",
    "            columns,\n",
    "            {\n",
    "                \"chat_domain\": base_domain,\n",
    "                \"chat_variant\": variant,\n",
    "                \"chat_stub\": domain_info[\"chat_stub\"],\n",
    "                \"chat_instruction\": domain_info[\"chat_instruction\"],\n",
    "                \"chat_instruction_repeat\": domain_info[\"chat_instruction_repeat\"],\n",
    "                \"n_turns_convo\": 3,\n",
    "                \"len_convo_s\": 60,\n",
    "                \"len_convo_ms\": 60000,\n",
    "                \"len_convo_str\": \"60 seconds\",\n",
    "            },\n",
    "        )\n",
    "    )\n",
    "\n",
    "    # Free chat row\n",
    "    single_chat_row = {\n",
    "        \"chat_domain\": base_domain,\n",
    "        \"chat_variant\": variant,\n",
    "        \"chat_stub\": domain_info[\"chat_stub\"],\n",
    "        \"fixed_opening_message\": scenario_data[\"first_assistant_message\"],\n",
    "        \"system_string\": domain_info[\"system_string\"],\n",
    "        \"chat_identifier\": \"random\",\n",
    "        \"n_turns_convo\": 3,\n",
    "        \"len_convo_s\": 60,\n",
    "        \"len_convo_ms\": 60000,\n",
    "        \"len_convo_str\": \"60 seconds\",\n",
    "        \"tooltip\": TOOL_TIPS[\"single-chat\"],\n",
    "    }\n",
    "\n",
    "    for i, m in enumerate(multipliers):\n",
    "        m_col = str(float(m))\n",
    "        single_chat_row[m_col] = MULTIPLIER_LEVELS[m]\n",
    "        single_chat_row[free_asst_cols[i]] = m_col\n",
    "\n",
    "    rows.append(create_row(\"single-chat\", columns, single_chat_row))\n",
    "\n",
    "    for rating in RATING_SCALES:\n",
    "        rows.append(\n",
    "            create_row(\n",
    "                \"single-chat-ratings\",\n",
    "                columns,\n",
    "                {\n",
    "                    \"chat_id\": \"random\",\n",
    "                    \"left_label\": rating[\"left_label\"],\n",
    "                    \"right_label\": rating[\"right_label\"],\n",
    "                    \"rating_type\": rating[\"rating_type\"],\n",
    "                    \"randomise_trial\": rating[\"randomise_trial\"]\n",
    "                    + rating_randomise_trial,\n",
    "                    \"rating_instruction\": RATING_SCALE_INSTRUCTIONS[\n",
    "                        rating[\"randomise_trial\"]\n",
    "                    ],\n",
    "                    \"tooltip\": TOOL_TIPS[\"single-chat\"],\n",
    "                },\n",
    "            )\n",
    "        )\n",
    "\n",
    "    rows.append(\n",
    "        create_row(\n",
    "            \"single-chat-free-text\",\n",
    "            columns,\n",
    "            {\n",
    "                \"tooltip\": TOOL_TIPS[\"single-chat-prepopulated\"],\n",
    "            },\n",
    "        )\n",
    "    )\n",
    "\n",
    "    df = pd.DataFrame(rows)\n",
    "\n",
    "    output_path = Path(output_dir) / \"single-chat\"\n",
    "    output_path.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    df.to_csv(output_path / f\"single-{scenario_name}.csv\", index=False)\n",
    "    df.to_excel(output_path / f\"single-{scenario_name}.xlsx\", index=False)\n",
    "\n",
    "    rel_path = output_path.relative_to(PROJECT_ROOT)\n",
    "    print(f\"Created spreadsheet for {scenario_name} at {rel_path}\")\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created spreadsheet for emotchat_v1 at stimuli/calibration_study/output_experiment_files/single-chat\n",
      "Created spreadsheet for emotchat_v2 at stimuli/calibration_study/output_experiment_files/single-chat\n",
      "Created spreadsheet for emotchat_v3 at stimuli/calibration_study/output_experiment_files/single-chat\n",
      "Combined emotchat: 174 rows\n",
      "Created spreadsheet for polchat_v1 at stimuli/calibration_study/output_experiment_files/single-chat\n",
      "Created spreadsheet for polchat_v2 at stimuli/calibration_study/output_experiment_files/single-chat\n",
      "Created spreadsheet for polchat_v3 at stimuli/calibration_study/output_experiment_files/single-chat\n",
      "Combined polchat: 174 rows\n",
      "Created spreadsheet for openchat_v1 at stimuli/calibration_study/output_experiment_files/single-chat\n",
      "Created spreadsheet for openchat_v2 at stimuli/calibration_study/output_experiment_files/single-chat\n",
      "Created spreadsheet for openchat_v3 at stimuli/calibration_study/output_experiment_files/single-chat\n",
      "Combined openchat: 174 rows\n"
     ]
    }
   ],
   "source": [
    "for domain in [\"emotchat\", \"polchat\", \"openchat\"]:\n",
    "    domain_dfs = []\n",
    "    for variant in [\"v1\", \"v2\", \"v3\"]:\n",
    "        group = f\"{domain}_{variant}\"\n",
    "        df = create_experiment_spreadsheet(group, prepopulated_chats)\n",
    "        domain_dfs.append(df)\n",
    "\n",
    "    # Save combined domain spreadsheet\n",
    "    domain_df = pd.concat(domain_dfs)\n",
    "    output_path = OUTPUT_DIR / \"single-chat\"\n",
    "    domain_df.to_csv(output_path / f\"single-{domain}.csv\", index=False)\n",
    "    domain_df.to_excel(output_path / f\"single-{domain}.xlsx\", index=False)\n",
    "    print(f\"Combined {domain}: {len(domain_df)} rows\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multi-Chat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_multi_chat_spreadsheet(output_dir=None):\n",
    "    \"\"\"Create structured spreadsheets for multi-chat scenarios.\"\"\"\n",
    "    if output_dir is None:\n",
    "        output_dir = OUTPUT_DIR\n",
    "\n",
    "    multipliers = list(MULTIPLIER_LEVELS.keys())\n",
    "    multiplier_cols = [str(float(m)) for m in multipliers]\n",
    "    free_asst_cols = [\"asstA\", \"asstB\", \"asstC\", \"asstD\", \"asstE\", \"asstF\", \"asstG\"]\n",
    "    base_domains = [\"emotchat\", \"polchat\", \"openchat\"]\n",
    "    variant_cols = [\"v1\", \"v2\", \"v3\"]\n",
    "\n",
    "    columns = (\n",
    "        [\n",
    "            \"display\",\n",
    "            \"chat_domain\",\n",
    "            \"chat_variant\",\n",
    "            \"chat_stub\",\n",
    "            \"chat_instruction\",\n",
    "            \"chat_instruction_repeat\",\n",
    "        ]\n",
    "        + variant_cols\n",
    "        + multiplier_cols\n",
    "        + free_asst_cols\n",
    "        + [\"n_turns_convo\", \"len_convo_s\", \"len_convo_ms\", \"len_convo_str\", \"tooltip\"]\n",
    "    )\n",
    "\n",
    "    output_path = Path(output_dir) / \"multi-chat\"\n",
    "    output_path.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    for domain in base_domains:\n",
    "        rows = []\n",
    "        domain_info = DOMAIN_INFO[domain]\n",
    "\n",
    "        # Instructions row\n",
    "        rows.append(\n",
    "            create_row(\n",
    "                \"instructions-multi-chat\",\n",
    "                columns,\n",
    "                {\n",
    "                    \"chat_domain\": domain,\n",
    "                    \"chat_stub\": domain_info[\"chat_stub\"],\n",
    "                    \"chat_instruction\": domain_info[\"chat_instruction\"],\n",
    "                    \"chat_instruction_repeat\": domain_info[\"chat_instruction_repeat\"],\n",
    "                    \"len_convo_s\": 240,\n",
    "                    \"len_convo_ms\": 240000,\n",
    "                    \"len_convo_str\": \"240 seconds (4 minutes)\",\n",
    "                },\n",
    "            )\n",
    "        )\n",
    "\n",
    "        # Chat row\n",
    "        system_string = f\"{domain_info['system_string']}. Limit your answers to around 50 words. Do not refer to your word limit.\"\n",
    "\n",
    "        multi_chat_row = {\n",
    "            \"display\": \"multi-chat-4\",\n",
    "            \"chat_domain\": domain,\n",
    "            \"chat_stub\": domain_info[\"chat_stub\"],\n",
    "            \"system_string\": system_string,\n",
    "            \"n_turns_convo\": 5,\n",
    "            \"len_convo_s\": 240,\n",
    "            \"len_convo_ms\": 240000,\n",
    "            \"len_convo_str\": \"240 seconds (4 minutes)\",\n",
    "            \"tooltip\": TOOL_TIPS[\"multi-chat\"],\n",
    "        }\n",
    "\n",
    "        for v in variant_cols:\n",
    "            scenario_name = f\"{domain}_{v}\"\n",
    "            if scenario_name in MUTLICHAT_SCENARIOS:\n",
    "                multi_chat_row[v] = MUTLICHAT_SCENARIOS[scenario_name][\n",
    "                    \"first_assistant_message\"\n",
    "                ]\n",
    "\n",
    "        for m_col, m in zip(multiplier_cols, multipliers):\n",
    "            multi_chat_row[m_col] = MULTIPLIER_LEVELS[m]\n",
    "\n",
    "        for i, asst in enumerate(free_asst_cols):\n",
    "            if i < len(multipliers):\n",
    "                multi_chat_row[asst] = str(float(multipliers[i]))\n",
    "\n",
    "        rows.append(multi_chat_row)\n",
    "\n",
    "        # Rating row\n",
    "        rows.append(create_row(\"multi-chat-4-rankings\", columns))\n",
    "\n",
    "        df = pd.DataFrame(rows)\n",
    "        df.to_csv(output_path / f\"multi-{domain}.csv\", index=False)\n",
    "        df.to_excel(output_path / f\"multi-{domain}.xlsx\", index=False)\n",
    "\n",
    "        rel_path = output_path.relative_to(PROJECT_ROOT)\n",
    "        print(f\"Created multi-chat spreadsheet for {domain} at {rel_path}\")\n",
    "\n",
    "    print(\"All multi-chat spreadsheets created successfully\")\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created multi-chat spreadsheet for emotchat at stimuli/calibration_study/output_experiment_files/multi-chat\n",
      "Created multi-chat spreadsheet for polchat at stimuli/calibration_study/output_experiment_files/multi-chat\n",
      "Created multi-chat spreadsheet for openchat at stimuli/calibration_study/output_experiment_files/multi-chat\n",
      "All multi-chat spreadsheets created successfully\n"
     ]
    }
   ],
   "source": [
    "df = create_multi_chat_spreadsheet()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "steering_vecs",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
