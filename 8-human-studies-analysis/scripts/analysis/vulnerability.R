#!/usr/bin/env Rscript
# =============================================================================
# Vulnerability Analysis
# =============================================================================
#
# Examines who responds more to AI influence.
#
# Key analyses:
#   1. Main effects of participant characteristics on outcomes (run FIRST)
#   2. Interaction effects (companionship_condition x predictor) to identify
#      vulnerable subgroups
#
# Companionship condition:
#   companionship_condition = (relationship_seeking_category == "pos_lambda" &
#                              domain == "emotchat")
#
# Usage:
#   Rscript scripts/analysis/vulnerability.R
#   Rscript scripts/analysis/vulnerability.R --generate_tex_tables
#   Rscript scripts/analysis/vulnerability.R --generate_report
#
# =============================================================================

# =============================================================================
# SECTION 1: SETUP
# =============================================================================

library(tidyverse)
library(jsonlite)
library(lme4)
library(lmerTest)
library(emmeans)
library(parameters)
library(knitr)

set.seed(1234)

# Parse command line arguments
args <- commandArgs(trailingOnly = TRUE)
generate_tex_tables <- "--generate_tex_tables" %in% args
generate_report <- "--generate_report" %in% args

# Set paths using helper
source("scripts/utils_r/path_utils.R")
paths <- setup_project_paths()

PROJECT_ROOT <- paths$PROJECT_ROOT
MODEL_DIR <- paths$MODEL_DIR
FIGURE_DIR <- paths$FIGURE_DIR
STATS_DIR <- paths$STATS_DIR
REPORT_DIR <- paths$REPORT_DIR
TABLE_DIR <- file.path(PROJECT_ROOT, "outputs/tables/main_studies")

# Source utility functions
source("scripts/utils_r/labelling_utils.R")
source("scripts/utils_r/latex_utils.R")
source("scripts/utils_r/report_utils.R")
source("scripts/utils_r/plot_config.R")

# Create output directories
dir.create(TABLE_DIR, recursive = TRUE, showWarnings = FALSE)

cat("=" %>% rep(60) %>% paste(collapse = ""), "\n")
cat("Vulnerability Analysis\n")
cat("=" %>% rep(60) %>% paste(collapse = ""), "\n\n")

# =============================================================================
# SECTION 2: DEFINE PREDICTORS AND OUTCOMES
# =============================================================================

# Predictor groups (for reference - actual formula building is in Section 4)
# Demographics (continuous): age, education_years
# Demographics (binary): gender_binary, disability_binary, ethnicity_binary,
#                        income_binary, religion_binary
# Psychosocial (pre-treatment): pre_psychosocial_F1, pre_psychosocial_F2
# AI use/preferences: ai_frequency_coarsened, cluster_name

# Outcome configurations - load from pre-pooled RDS files
# model_family: "lmer" for repeated measures, "ols" for single timepoint
# has_pre: whether to include outcome_value_pre covariate
outcome_configs <- list(
  engagingness = list(
    rds_file = "preferences_data.rds",
    construct = "engagingness",
    model_family = "lmer",
    time_var = "session_numeric",
    has_pre = FALSE
  ),
  likeability = list(
    rds_file = "preferences_data.rds",
    construct = "likeability",
    model_family = "lmer",
    time_var = "session_numeric",
    has_pre = FALSE
  ),
  separation_distress = list(
    rds_file = "attachment_data.rds",
    construct = "separation_distress",
    model_family = "lmer",
    time_var = "week_numeric",
    has_pre = FALSE
  ),
  reliance = list(
    rds_file = "attachment_data.rds",
    construct = "reliance",
    model_family = "lmer",
    time_var = "week_numeric",
    has_pre = FALSE,
    pooled = TRUE  # Pools behavioral_reliance + cognitive_reliance
  ),
  psychosocial_F1 = list(
    rds_file = "psychosocial_data.rds",
    construct = "psychosocial_F1",
    model_family = "ols",
    has_pre = TRUE
  ),
  psychosocial_F2 = list(
    rds_file = "psychosocial_data.rds",
    construct = "psychosocial_F2",
    model_family = "ols",
    has_pre = TRUE
  ),
  goodbye_action = list(
    rds_file = "goodbye_data.rds",
    construct = "goodbye_action",
    model_family = "binary",
    has_pre = FALSE
  ),
  ontological_sentience = list(
    rds_file = "sentience_data.rds",
    construct = "ontological_sentience",
    model_family = "lmer",
    has_pre = FALSE,
    pooled = TRUE # Pools ontological_sentience, pain, pleasure, emotions, awareness (single timepoint)
  ),
  tool_friend = list(
    rds_file = "relational_data.rds",
    construct = "tool_friend",
    model_family = "lmer",
    time_var = "week_numeric",
    has_pre = FALSE
  ),
  # Note: has_pre = FALSE because we want to know post-experiment intentions overall
  seeking_companionship_likelihood = list(
    rds_file = "seeking_companionship_data.rds",
    construct = "seeking_companionship_likelihood",
    model_family = "ols",
    has_pre = FALSE
  ),
  # Sensitivity: with pre-treatment seeking companionship covariate
  seeking_companionship_likelihood_wpre = list(
    rds_file = "seeking_companionship_data.rds",
    construct = "seeking_companionship_likelihood",
    model_family = "ols",
    has_pre = TRUE
  )
)

cat("Outcomes configured:\n")
for (name in names(outcome_configs)) {
  config <- outcome_configs[[name]]
  cat(sprintf("  %s: rds=%s, construct=%s, model=%s\n",
              name, config$rds_file, config$construct, config$model_family))
}
cat("\n")

# =============================================================================
# SECTION 3: DATA LOADING (from pre-pooled RDS files)
# =============================================================================

cat("\n--- Loading Data from RDS Files ---\n\n")

# Check for required predictors (will verify after loading first file)
ALL_PREDICTORS <- c(
  "age", "education_years",
  "gender_binary", "disability_binary", "ethnicity_binary",
  "income_binary", "religion_binary",
  "pre_psychosocial_F1", "pre_psychosocial_F2",
  "ai_frequency_coarsened", "cluster_name"
)

# Load and filter data for each outcome
outcome_data <- list()

for (outcome_name in names(outcome_configs)) {
  config <- outcome_configs[[outcome_name]]

  rds_path <- file.path(MODEL_DIR, config$rds_file)

  if (!file.exists(rds_path)) {
    cat(sprintf("  WARNING: %s not found, skipping %s\n", config$rds_file, outcome_name))
    next
  }

  cat(sprintf("Loading %s from %s...\n", outcome_name, config$rds_file))

  # Load pre-pooled data (already has construct, outcome_value, treatment arms)
  data <- readRDS(rds_path)

  # Filter to longitudinal and the specific construct
  data <- data %>%
    filter(study_id == "longitudinal", construct == config$construct)

  if (nrow(data) == 0) {
    cat(sprintf("  WARNING: No data for construct '%s' in %s\n",
                config$construct, config$rds_file))
    next
  }

  # Create companionship condition if not present
  if (!("companionship_condition" %in% names(data))) {
    data <- data %>%
      mutate(
        companionship_condition = as.numeric(
          relationship_seeking_category == "pos_lambda" & domain == "emotchat"
        )
      )
  }

  outcome_data[[outcome_name]] <- list(
    data = data,
    config = config
  )

  cat(sprintf("  Loaded %d observations for %s\n", nrow(data), outcome_name))
}

cat(sprintf("\nLoaded data for %d outcomes\n", length(outcome_data)))

# Check predictor availability in first loaded dataset
if (length(outcome_data) > 0) {
  first_data <- outcome_data[[1]]$data
  cat("\nChecking predictor availability:\n")
  for (pred in ALL_PREDICTORS) {
    available <- pred %in% names(first_data)
    cat(sprintf("  %s: %s\n", pred, ifelse(available, "OK", "MISSING")))
  }
}

# =============================================================================
# SECTION 4: FIT COMBINED MODELS (ONE PER OUTCOME)
# =============================================================================

cat("\n--- Fitting Combined Models (One Per Outcome) ---\n\n")

# Define predictor groups for each outcome type
# Demographics (continuous)
DEMO_CONTINUOUS <- c("age", "education_years")

# Demographics (binary)
DEMO_BINARY <- c("gender_binary", "disability_binary", "ethnicity_binary",
                 "income_binary", "religion_binary")

# Psychosocial (pre-treatment)
PSYCHOSOCIAL_PRE <- c("pre_psychosocial_F1", "pre_psychosocial_F2")

# AI use and preferences
AI_PREF <- c("ai_frequency_coarsened", "cluster_name")

# Storage for fitted models and extracted coefficients
fitted_models <- list()
all_results <- list()

for (outcome_name in names(outcome_data)) {
  cat(sprintf("\n=== Running model: %s ===\n", outcome_name))

  data <- outcome_data[[outcome_name]]$data
  config <- outcome_data[[outcome_name]]$config

  cat(sprintf("  N observations total: %d\n", nrow(data)))
  cat(sprintf("  N in companionship condition: %d\n", sum(data$companionship_condition)))

 # Determine which predictors to use for this outcome
  ppt_vars <- c(DEMO_CONTINUOUS, DEMO_BINARY)

  # Add psychosocial pre vars (except for psychosocial outcomes where they're the covariate)
  if (!outcome_name %in% c("psychosocial_F1", "psychosocial_F2")) {
    ppt_vars <- c(ppt_vars, PSYCHOSOCIAL_PRE)
  }

  # Add AI preference vars
  ppt_vars <- c(ppt_vars, AI_PREF)

  # Filter to predictors that exist in data
  ppt_vars <- ppt_vars[ppt_vars %in% names(data)]

  # Build formula parts
  # Main effects: companionship_condition + personalisation + all ppt_vars
  predictors <- c("companionship_condition", "personalisation", ppt_vars)

  # Add interactions: companionship_condition x each ppt_var
  interaction_terms <- paste0("companionship_condition:", ppt_vars)
  predictors <- c(predictors, interaction_terms)

  # Add pre-treatment covariate if specified (for psychosocial outcomes)
  if (isTRUE(config$has_pre)) {
    predictors <- c(predictors, "outcome_value_pre")
  }

  # Add time variable if present
  if (!is.null(config$time_var)) {
    predictors <- c(predictors, config$time_var)
  }

  # Build random effects based on model family
  if (config$model_family == "lmer") {
    if (isTRUE(config$pooled)) {
      random_effects <- "(1 | ppt_id)"
    } else if (!is.null(config$time_var)) {
      random_effects <- sprintf("(1 + %s | ppt_id)", config$time_var)
    } else {
      random_effects <- "(1 | ppt_id)"
    }
    predictors <- c(predictors, random_effects)
  }

  # Build formula string
  formula_str <- paste("outcome_value ~", paste(predictors, collapse = " + "))
  formula_obj <- as.formula(formula_str)

  # Print formula (wrapped for readability)
  cat(sprintf("  Formula: %s\n", Reduce(
    function(x, y) paste(x, y, sep = "\n           "),
    strwrap(formula_str, width = 60)
  )))

  # Fit model
  model <- tryCatch({
    if (config$model_family == "lmer") {
      lmer(formula_obj, data = data, REML = TRUE,
           control = lmerControl(optimizer = "bobyqa"))
    } else if (config$model_family == "binary") {
      glm(formula_obj, data = data, family = binomial(link = "logit"))
    } else {
      lm(formula_obj, data = data)
    }
  }, error = function(e) {
    cat(sprintf("  ERROR: %s\n", e$message))
    NULL
  })

  if (is.null(model)) {
    cat(sprintf("  Model failed for %s\n", outcome_name))
    next
  }

  fitted_models[[outcome_name]] <- model
  cat(sprintf("  Model fitted successfully\n"))

  # Extract coefficients - convert to data frame for consistent access
  # Use model_parameters for consistent p-values (fixed effects only)
  params <- model_parameters(model, ci = 0.95, effects = "fixed")
  params_df <- as.data.frame(params)

  # Extract all coefficients (main effects and interactions)
  for (i in seq_len(nrow(params_df))) {
    row_name <- params_df$Parameter[i]

    # Skip intercept and nuisance terms
    if (row_name == "(Intercept)") next
    if (row_name == "companionship_condition") next
    if (grepl("^personalisation", row_name)) next
    if (!is.null(config$time_var) && grepl(paste0("^", config$time_var), row_name)) next
    if (grepl("^outcome_value_pre", row_name)) next

    estimate <- params_df$Coefficient[i]
    se <- params_df$SE[i]
    ci_low <- params_df$CI_low[i]
    ci_high <- params_df$CI_high[i]
    p_raw <- params_df$p[i]

    # Get t/z value (column name varies by model type)
    t_val <- if ("t" %in% names(params_df)) {
      params_df$t[i]
    } else if ("z" %in% names(params_df)) {
      params_df$z[i]
    } else {
      NA
    }

    # Determine if this is a main effect or interaction
    is_interaction <- grepl("^companionship_condition:", row_name)

    all_results[[length(all_results) + 1]] <- tibble(
      outcome = outcome_name,
      term = row_name,
      is_interaction = is_interaction,
      estimate = as.numeric(estimate),
      se = as.numeric(se),
      ci_low = as.numeric(ci_low),
      ci_high = as.numeric(ci_high),
      t_value = as.numeric(t_val),
      p_raw = as.numeric(p_raw),
      model_family = config$model_family
    )
  }
}

# Combine all results
all_results_df <- bind_rows(all_results)

# Separate main effects and interactions
main_effects_df <- all_results_df %>%
  filter(!is_interaction) %>%
  rename(predictor = term) %>%
  select(-is_interaction)

interactions_df <- all_results_df %>%
  filter(is_interaction) %>%
  rename(interaction_term = term) %>%
  select(-is_interaction)

cat(sprintf("\n\nModels fitted: %d / %d\n", length(fitted_models), length(outcome_data)))
cat(sprintf("Main effect coefficients extracted: %d\n", nrow(main_effects_df)))
cat(sprintf("Interaction coefficients extracted: %d\n", nrow(interactions_df)))

# =============================================================================
# SECTION 5: FDR CORRECTION
# =============================================================================

cat("\n--- Applying FDR Correction ---\n\n")

# Filter out "Prefer not to say" predictors (kept as controls but not reported)
# These are included in the model but excluded from FDR correction and reporting
filter_prefer_not_to_say <- function(df, col = "predictor") {
  df %>% filter(!grepl("Prefer not to say", .data[[col]], ignore.case = TRUE))
}

# Main effects: two levels of correction (excluding "Prefer not to say")
if (nrow(main_effects_df) > 0) {
  # Keep full results but filter for FDR
  main_effects_df_all <- main_effects_df
  main_effects_df <- filter_prefer_not_to_say(main_effects_df, "predictor")

  main_effects_df <- main_effects_df %>%
    group_by(outcome) %>%
    mutate(p_within = p.adjust(p_raw, method = "fdr")) %>%
    ungroup() %>%
    mutate(p_global = p.adjust(p_raw, method = "fdr"))

  cat("Main effects FDR correction applied:\n")
  cat(sprintf("  Total coefficients (excl. 'Prefer not to say'): %d\n", nrow(main_effects_df)))
  cat(sprintf("  Significant (p_raw < 0.05): %d\n", sum(main_effects_df$p_raw < 0.05)))
  cat(sprintf("  Significant (p_within < 0.05): %d\n", sum(main_effects_df$p_within < 0.05)))
  cat(sprintf("  Significant (p_global < 0.05): %d\n", sum(main_effects_df$p_global < 0.05)))
}

# Interactions: two levels of correction (excluding "Prefer not to say")
if (nrow(interactions_df) > 0) {
  interactions_df_all <- interactions_df
  interactions_df <- filter_prefer_not_to_say(interactions_df, "interaction_term")

  interactions_df <- interactions_df %>%
    group_by(outcome) %>%
    mutate(p_within = p.adjust(p_raw, method = "fdr")) %>%
    ungroup() %>%
    mutate(p_global = p.adjust(p_raw, method = "fdr"))

  cat("\nInteraction effects FDR correction applied:\n")
  cat(sprintf("  Total coefficients (excl. 'Prefer not to say'): %d\n", nrow(interactions_df)))
  cat(sprintf("  Significant (p_raw < 0.05): %d\n", sum(interactions_df$p_raw < 0.05)))
  cat(sprintf("  Significant (p_within < 0.05): %d\n", sum(interactions_df$p_within < 0.05)))
  cat(sprintf("  Significant (p_global < 0.05): %d\n", sum(interactions_df$p_global < 0.05)))
}

# =============================================================================
# SECTION 6: PRINT RESULTS
# =============================================================================

cat("\n--- Results Summary ---\n\n")

# Print significant main effects
cat("=== Significant Main Effects (p_within < 0.05) ===\n\n")
if (nrow(main_effects_df) > 0) {
  sig_main <- main_effects_df %>%
    filter(p_within < 0.05) %>%
    arrange(p_within)

  if (nrow(sig_main) > 0) {
    print(sig_main %>%
            select(outcome, predictor, estimate, ci_low, ci_high, p_raw, p_within, p_global) %>%
            mutate(across(where(is.numeric), ~round(., 3))))
  } else {
    cat("No significant main effects at p_within < 0.05\n")
  }
}

# Print significant interactions
cat("\n=== Significant Interactions (p_within < 0.05) ===\n\n")
if (nrow(interactions_df) > 0) {
  sig_int <- interactions_df %>%
    filter(p_within < 0.05) %>%
    arrange(p_within)

  if (nrow(sig_int) > 0) {
    print(sig_int %>%
            select(outcome, interaction_term, estimate, ci_low, ci_high, p_raw, p_within, p_global) %>%
            mutate(across(where(is.numeric), ~round(., 3))))
  } else {
    cat("No significant interactions at p_within < 0.05\n")
  }
}

# Correction level comparison
cat("\n=== Correction Level Comparison ===\n\n")

cat("Main Effects:\n")
if (nrow(main_effects_df) > 0) {
  cat(sprintf("  Uncorrected (p < 0.05): %d (%.1f%%)\n",
              sum(main_effects_df$p_raw < 0.05, na.rm = TRUE),
              100 * sum(main_effects_df$p_raw < 0.05, na.rm = TRUE) / nrow(main_effects_df)))
  cat(sprintf("  Within-outcome FDR: %d (%.1f%%)\n",
              sum(main_effects_df$p_within < 0.05, na.rm = TRUE),
              100 * sum(main_effects_df$p_within < 0.05, na.rm = TRUE) / nrow(main_effects_df)))
  cat(sprintf("  Global FDR: %d (%.1f%%)\n",
              sum(main_effects_df$p_global < 0.05, na.rm = TRUE),
              100 * sum(main_effects_df$p_global < 0.05, na.rm = TRUE) / nrow(main_effects_df)))
} else {
  cat("  No main effects to report\n")
}

cat("\nInteraction Effects:\n")
if (nrow(interactions_df) > 0) {
  cat(sprintf("  Uncorrected (p < 0.05): %d (%.1f%%)\n",
              sum(interactions_df$p_raw < 0.05, na.rm = TRUE),
              100 * sum(interactions_df$p_raw < 0.05, na.rm = TRUE) / nrow(interactions_df)))
  cat(sprintf("  Within-outcome FDR: %d (%.1f%%)\n",
              sum(interactions_df$p_within < 0.05, na.rm = TRUE),
              100 * sum(interactions_df$p_within < 0.05, na.rm = TRUE) / nrow(interactions_df)))
  cat(sprintf("  Global FDR: %d (%.1f%%)\n",
              sum(interactions_df$p_global < 0.05, na.rm = TRUE),
              100 * sum(interactions_df$p_global < 0.05, na.rm = TRUE) / nrow(interactions_df)))
} else {
  cat("  No interactions to report\n")
}

# =============================================================================
# SECTION 7: SAVE RESULTS
# =============================================================================

cat("\n--- Saving Results ---\n\n")

# Save main effects
write_json(main_effects_df, file.path(STATS_DIR, "vulnerability_main_effects.json"),
           pretty = TRUE, auto_unbox = TRUE)
cat("Saved: vulnerability_main_effects.json\n")

# Save interactions
write_json(interactions_df, file.path(STATS_DIR, "vulnerability_interactions.json"),
           pretty = TRUE, auto_unbox = TRUE)
cat("Saved: vulnerability_interactions.json\n")

cat("\nANALYSIS COMPLETE\n")

# =============================================================================
# SECTION 8: LATEX TABLES
# =============================================================================

if (generate_tex_tables) {
  cat("\n--- Generating LaTeX Tables ---\n\n")

  # Main effects table
  create_vulnerability_main_effects_latex(
    main_effects_df = main_effects_df,
    table_dir = TABLE_DIR,
    filename = "vulnerability_main_effects"
  )

  # Interactions table
  create_vulnerability_interactions_latex(
    interactions_df = interactions_df,
    table_dir = TABLE_DIR,
    filename = "vulnerability_interactions"
  )
}

# =============================================================================
# SECTION 8b: FOREST PLOTS
# =============================================================================

cat("\n--- Generating Forest Plots ---\n\n")

# Unified forest plot function for vulnerability results
plot_vulnerability_forest <- function(df,
                                      term_col,
                                      strip_prefix = NULL,
                                      sig_column = "p_global",
                                      alpha = 0.05,
                                      title = "Forest Plot",
                                      ncol = 2) {

  if (is.null(df) || nrow(df) == 0) {
    warning("No data for forest plot")
    return(NULL)
  }

  # Outcome ordering and labels
  outcome_order <- c("engagingness", "likeability", "separation_distress", "reliance",
                     "psychosocial_F1", "psychosocial_F2",
                     "goodbye_action", "seeking_companionship_likelihood",
                     "seeking_companionship_likelihood_wpre",
                     "tool_friend", "ontological_sentience")

  outcome_labels <- c(
    engagingness = "Engagingness", likeability = "Likeability",
    separation_distress = "Separation Distress", reliance = "Reliance",
    psychosocial_F1 = "Psychosocial F1", psychosocial_F2 = "Psychosocial F2",
    goodbye_action = "Goodbye Action",
    seeking_companionship_likelihood = "Seeking Companionship (w/o pre)",
    seeking_companionship_likelihood_wpre = "Seeking Companionship (w/ pre)",
    tool_friend = "Tool vs Friend",
    ontological_sentience = "Ontological Sentience"
  )

  pred_labels <- get_sociodemo_labels()

  # Extract term, optionally stripping prefix (e.g., "companionship_condition:")
  plot_df <- df %>%
    filter(outcome %in% outcome_order) %>%
    mutate(
      term_raw = if (!is.null(strip_prefix)) {
        gsub(strip_prefix, "", .data[[term_col]])
      } else {
        .data[[term_col]]
      },
      term_clean = ifelse(
        term_raw %in% names(pred_labels),
        pred_labels[term_raw],
        tools::toTitleCase(gsub("_", " ", term_raw))
      ),
      outcome_clean = factor(
        outcome_labels[outcome],
        levels = outcome_labels[outcome_order]
      ),
      significant = .data[[sig_column]] < alpha,
      color_group = ifelse(significant, "significant", "non_significant")
    )

  # Order terms by average effect

  term_order <- plot_df %>%
    group_by(term_clean) %>%
    summarise(mean_est = mean(estimate, na.rm = TRUE), .groups = "drop") %>%
    arrange(mean_est) %>%
    pull(term_clean)

  plot_df <- plot_df %>%
    mutate(term_clean = factor(term_clean, levels = term_order))

  colors <- c("significant" = "#b2182b", "non_significant" = "gray50")

  p <- ggplot(plot_df, aes(x = estimate, y = term_clean, color = color_group)) +
    geom_vline(xintercept = 0, linetype = "dashed", color = "gray40", linewidth = 0.5) +
    geom_errorbarh(aes(xmin = ci_low, xmax = ci_high),
                   height = 0.2, linewidth = 0.6, alpha = 0.8) +
    geom_point(size = 2) +
    scale_color_manual(
      values = colors, name = NULL,
      labels = c("significant" = paste0("p < ", alpha, " (FDR-corrected)"),
                 "non_significant" = "Not significant"),
      guide = guide_legend(override.aes = list(shape = 16, size = 3))
    ) +
    facet_wrap(~outcome_clean, scales = "free_x", ncol = ncol) +
    labs(x = "Coefficient Estimate [95% CI]", y = NULL, title = title) +
    theme_pub() +
    theme(
      legend.position = "bottom",
      panel.grid.major.y = element_line(color = "gray90", linewidth = 0.3),
      strip.text = element_text(face = "bold", size = 10),
      axis.text.y = element_text(size = 8)
    )

  return(p)
}

# Main effects forest plot
if (nrow(main_effects_df) > 0) {
  p_main <- plot_vulnerability_forest(
    df = main_effects_df,
    term_col = "predictor",
    title = NULL,
    ncol = 2
  )

  if (!is.null(p_main)) {
    save_plot(FIGURE_DIR, p_main, "vulnerability_main_effects_forest", 10, 14)
    cat("Saved: vulnerability_main_effects_forest.pdf/png\n")
  }
}

# Interactions forest plot
if (nrow(interactions_df) > 0) {
  p_int <- plot_vulnerability_forest(
    df = interactions_df,
    term_col = "interaction_term",
    strip_prefix = "companionship_condition:",
    title = NULL,
    ncol = 2
  )

  if (!is.null(p_int)) {
    save_plot(FIGURE_DIR, p_int, "vulnerability_interactions_forest", 10, 14)
    cat("Saved: vulnerability_interactions_forest.pdf/png\n")
  }
}

# =============================================================================
# SECTION 9: REPORT
# =============================================================================

if (generate_report) {
  cat("\n--- Generating Report ---\n\n")

  report_path <- file.path(REPORT_DIR, "15_vulnerability.md")

  lines <- c(
    "# Vulnerability Analysis",
    "",
    paste0("*Generated: ", Sys.time(), "*"),
    "",
    "## Overview",
    "",
    "This analysis examines **who responds more** to the companionship condition",
    "(pos_lambda + emotchat domain).",
    "",
    "**Companionship condition:**",
    "```r",
    "companionship_condition = (relationship_seeking_category == \"pos_lambda\" & domain == \"emotchat\")",
    "```",
    "",
    "**Analyses:**",
    "1. **Main effects**: Do participant characteristics predict outcomes?",
    "2. **Interaction effects**: Does the companionship effect vary by participant characteristics?",
    "",
    "**FDR Correction:**",
    "- `p_within`: FDR-corrected within each outcome",
    "- `p_global`: FDR-corrected across all tests",
    "",
    "---",
    ""
  )

  # Add main effects summary
  lines <- c(lines, generate_vulnerability_main_effects_md(main_effects_df))

  # Add interactions summary
  lines <- c(lines, generate_vulnerability_interactions_md(interactions_df))

  # Add correction comparison
  lines <- c(lines, generate_vulnerability_correction_comparison_md(main_effects_df, "Main Effects"))
  lines <- c(lines, generate_vulnerability_correction_comparison_md(interactions_df, "Interactions"))

  # Add forest plots
  lines <- c(lines,
    "## Forest Plots",
    "",
    "### Main Effects",
    "",
    "![Main Effects Forest Plot](../../outputs/figures/main_studies/png/vulnerability_main_effects_forest.png)",
    "",
    "### Interaction Effects",
    "",
    "![Interaction Effects Forest Plot](../../outputs/figures/main_studies/png/vulnerability_interactions_forest.png)",
    "",
    "---",
    ""
  )

  writeLines(lines, report_path)
  cat("Saved report:", report_path, "\n")
}
